{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9859a8a5",
   "metadata": {},
   "source": [
    "# CS 543 Final Project: Grading of Diabetic Retinopathy Severity Level\n",
    "\n",
    "## Hongshuo Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31081362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "from PIL import Image, ImageOps\n",
    "import PIL\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bfdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "\n",
    "# https://www.kaggle.com/ratthachat/aptos-eye-preprocessing-in-diabetic-retinopathy#3.A-Important-Update-on-Color-Version-of-Cropping-&-Ben's-Preprocessing\n",
    "# https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Kaggles/DiabeticRetinopathy/train.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e2230",
   "metadata": {},
   "source": [
    "# Generate training vs testing vs validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac0db9",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/trainLabels_cropped.csv')\n",
    "\n",
    "y = df[['image','level']]\n",
    "SEED = 99\n",
    "\n",
    "y = shuffle(y, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68262d9",
   "metadata": {},
   "source": [
    "train_y, valid_y = train_test_split(y, test_size=0.3)\n",
    "valid_y, test_y = train_test_split(valid_y, test_size=1.0/3.0)\n",
    "\n",
    "train_y.shape, valid_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af295e",
   "metadata": {},
   "source": [
    "print(train_y['level'].value_counts())\n",
    "print(valid_y['level'].value_counts())\n",
    "\n",
    "train_y['level'].hist()\n",
    "valid_y['level'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fa4ee",
   "metadata": {},
   "source": [
    "print(test_y['level'].value_counts())\n",
    "test_y['level'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5258eb",
   "metadata": {},
   "source": [
    "train_y.to_csv('train_cropped.csv', index=False)\n",
    "\n",
    "valid_y.to_csv('val_cropped.csv', index=False)\n",
    "\n",
    "test_y.to_csv('test_cropped.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d348f2",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd70068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1441faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ben_color(img, sigmaX=10):\n",
    "    image = img\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765e923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(im):\n",
    "    \"\"\"\n",
    "    Converts image to grayscale using cv2, then computes binary matrix\n",
    "    of the pixels that are above a certain threshold, then takes out\n",
    "    the first row where a certain percetage of the pixels are above the\n",
    "    threshold will be the first clip point. Same idea for col, max row, max col.\n",
    "    \"\"\"\n",
    "    percentage = 0.02\n",
    "\n",
    "    img = np.array(im)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    im = img_gray > 0.1 * np.mean(img_gray[img_gray != 0])\n",
    "    row_sums = np.sum(im, axis=1)\n",
    "    col_sums = np.sum(im, axis=0)\n",
    "    rows = np.where(row_sums > img.shape[1] * percentage)[0]\n",
    "    cols = np.where(col_sums > img.shape[0] * percentage)[0]\n",
    "    min_row, min_col = np.min(rows), np.min(cols)\n",
    "    max_row, max_col = np.max(rows), np.max(cols)\n",
    "    im_crop = img[min_row : max_row + 1, min_col : max_col + 1]\n",
    "    return Image.fromarray(im_crop)\n",
    "\n",
    "def resize_maintain_aspect(image, desired_size):\n",
    "    \"\"\"\n",
    "    Stole this from some stackoverflow post but can't remember which,\n",
    "    this will add padding to maintain the aspect ratio.\n",
    "    \"\"\"\n",
    "    old_size = image.size  # old_size[0] is in (width, height) format\n",
    "    ratio = float(desired_size) / max(old_size)\n",
    "    new_size = tuple([int(x * ratio) for x in old_size])\n",
    "    im = image.resize(new_size, Image.ANTIALIAS)\n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size))\n",
    "    new_im.paste(im, ((desired_size - new_size[0]) // 2, (desired_size - new_size[1]) // 2))\n",
    "    return new_im\n",
    "\n",
    "def save_single(args):\n",
    "    img_file, input_path_folder, output_path_folder, output_size = args\n",
    "    image_original = Image.open(os.path.join(input_path_folder, img_file))\n",
    "    image = trim(image_original)\n",
    "    image = resize_maintain_aspect(image, desired_size=output_size[0])\n",
    "    image = load_ben_color(image,10)\n",
    "    image.save(os.path.join(output_path_folder + img_file))\n",
    "    \n",
    "def fast_image_resize(input_path_folder, output_path_folder, output_size=None):\n",
    "    \"\"\"\n",
    "    Uses multiprocessing to make it fast\n",
    "    \"\"\"\n",
    "    if not output_size:\n",
    "        warnings.warn(\"Need to specify output_size! For example: output_size=100\")\n",
    "        exit()\n",
    "\n",
    "    if not os.path.exists(output_path_folder):\n",
    "        os.makedirs(output_path_folder)\n",
    "\n",
    "    jobs = [\n",
    "        (file, input_path_folder, output_path_folder, output_size)\n",
    "        for file in os.listdir(input_path_folder)\n",
    "    ]\n",
    "\n",
    "    with Pool() as p:\n",
    "        list(tqdm(p.imap_unordered(save_single, jobs), total=len(jobs)))\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a89cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fast_image_resize(\"data\\\\aptos2019-blindness-detection\\\\train_images\\\\\", \"data\\\\aptos2019-blindness-detection\\\\train\\\\images_resized_512\\\\\", output_size=(512, 512))\n",
    "#fast_image_resize(\"data\\\\aptos2019-blindness-detection\\\\test_images\\\\\", \"data\\\\aptos2019-blindness-detection\\\\test\\\\images_resized_512\\\\\", output_size=(512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab2e7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from utils import save_checkpoint, load_checkpoint, check_accuracy\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import os\n",
    "import pandas as pd\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4804b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperperameter\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 3e-5\n",
    "WEIGHT_DECAY = 5e-4\n",
    "BATCH_SIZE = 10\n",
    "NUM_EPOCHS = 100\n",
    "NUM_WORKERS = 6\n",
    "CHECKPOINT_FILE = \"b3.pth.tar\"\n",
    "PIN_MEMORY = True\n",
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = True\n",
    "\n",
    "# Data augmentation for images\n",
    "input_size = 512\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=input_size, height=input_size),\n",
    "        A.RandomCrop(height=input_size-20, width=input_size-20),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Blur(p=0.3),\n",
    "        A.CLAHE(p=0.3),\n",
    "        A.ColorJitter(p=0.3),\n",
    "        A.CoarseDropout(max_holes=12, max_height=20, max_width=20, p=0.3),\n",
    "        A.IAAAffine(shear=30, rotate=0, p=0.2, mode=\"constant\"),\n",
    "        A.Normalize(\n",
    "            mean=[0.3199, 0.2240, 0.1609],\n",
    "            std=[0.3020, 0.2183, 0.1741],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=input_size-20, width=input_size-20),\n",
    "        A.Normalize(\n",
    "            mean=[0.3199, 0.2240, 0.1609],\n",
    "            std=[0.3020, 0.2183, 0.1741],\n",
    "            max_pixel_value=255.0,\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7fa0d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a924be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRDataset(Dataset):\n",
    "    def __init__(self, images_folder, path_to_csv, train=True, transform=None):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(path_to_csv)\n",
    "        self.images_folder = images_folder\n",
    "        self.image_files = os.listdir(images_folder)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0] #if self.train else len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            image_file, label = self.data.iloc[index]\n",
    "        else:\n",
    "            # if test simply return -1 for label, I do this in order to\n",
    "            # re-use same dataset class for test set submission later on\n",
    "            image_file, label = self.data.iloc[index]\n",
    "            image_file = image_file.replace(\".jpeg\", \"\")\n",
    "\n",
    "        image = np.array(Image.open(os.path.join(self.images_folder, image_file+\".jpeg\")))\n",
    "\n",
    "        if self.transform:\n",
    "            \n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image, label, image_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee74452",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9ea07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, loader, output_csv=\"submission.csv\"):\n",
    "    preds = []\n",
    "    filenames = []\n",
    "    model.eval()\n",
    "\n",
    "    for x, y, files in tqdm(loader):\n",
    "        x = x.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(x)\n",
    "            # Convert MSE floats to integer predictions\n",
    "            predictions[predictions < 0.5] = 0\n",
    "            predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n",
    "            predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n",
    "            predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n",
    "            predictions[(predictions >= 3.5) & (predictions < 10000000)] = 4\n",
    "            predictions = predictions.long().squeeze(1)\n",
    "            preds.append(predictions.cpu().numpy())\n",
    "            filenames += files\n",
    "\n",
    "    #df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n",
    "    df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    model.train()\n",
    "    print(\"Done with predictions\")\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for x, y, filename in tqdm(loader):\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(x)\n",
    "\n",
    "        # Convert MSE floats to integer predictions\n",
    "        predictions[predictions < 0.5] = 0\n",
    "        predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n",
    "        predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n",
    "        predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n",
    "        predictions[(predictions >= 3.5) & (predictions < 100)] = 4\n",
    "        predictions = predictions.long().view(-1)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        num_correct += (predictions == y).sum()\n",
    "        num_samples += predictions.shape[0]\n",
    "\n",
    "        # add to lists\n",
    "        all_preds.append(predictions.detach().cpu().numpy())\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "    print(\n",
    "        f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}\"\n",
    "    )\n",
    "    model.train()\n",
    "    return np.concatenate(all_preds, axis=0, dtype=np.int64), np.concatenate(\n",
    "        all_labels, axis=0, dtype=np.int64\n",
    "    )\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, scaler, device):\n",
    "    losses = []\n",
    "    loop = tqdm(loader)\n",
    "    for batch_idx, (data, targets, _) in enumerate(loop):\n",
    "        # save examples and make sure they look ok with the data augmentation,\n",
    "        # tip is to first set mean=[0,0,0], std=[1,1,1] so they look \"normal\"\n",
    "        #save_image(data, f\"hi_{batch_idx}.png\")\n",
    "\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "            scores = model(data)\n",
    "            loss = loss_fn(scores, targets.unsqueeze(1).float())\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Loss average over epoch: {sum(losses)/len(losses)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba032e9",
   "metadata": {},
   "source": [
    "train_ds = DRDataset(\n",
    "    #images_folder=\"train/images_preprocessed_1000/\",\n",
    "    #path_to_csv=\"train/trainLabels.csv\",\n",
    "\n",
    "    images_folder=\"data/resized_train/resized_train_300/\",\n",
    "    path_to_csv=\"train_cropped.csv\",\n",
    "\n",
    "    transform=config.train_transforms,\n",
    ")\n",
    "val_ds = DRDataset(\n",
    "    images_folder=\"data/resized_train/resized_train_300/\",\n",
    "    path_to_csv=\"val_cropped.csv\",\n",
    "    transform=config.val_transforms,\n",
    ")\n",
    "test_ds = DRDataset(\n",
    "    images_folder=\"data/resized_train/resized_train_300/\",\n",
    "    path_to_csv=\"test_cropped.csv\",\n",
    "    transform=config.val_transforms,\n",
    "    train=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=config.BATCH_SIZE, num_workers=6, shuffle=False\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    num_workers=2,\n",
    "    pin_memory=config.PIN_MEMORY,\n",
    "    shuffle=True,\n",
    ")\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b3\")\n",
    "model._fc = nn.Linear(1536, 1)\n",
    "model = model.to(config.DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "if config.LOAD_MODEL and config.CHECKPOINT_FILE in os.listdir():\n",
    "    load_checkpoint(torch.load(config.CHECKPOINT_FILE), model, optimizer, config.LEARNING_RATE)\n",
    "\n",
    "# Run after training is done and you've achieved good result\n",
    "# on validation set, then run train_blend.py file to use information\n",
    "# about both eyes concatenated\n",
    "#get_csv_for_blend(val_loader, model, \"data/aptos2019-blindness-detection/val_blend.csv\")\n",
    "#get_csv_for_blend(train_loader, model, \"data/aptos2019-blindness-detection/train_blend.csv\")\n",
    "#get_csv_for_blend(test_loader, model, \"data/aptos2019-blindness-detection/test_blend.csv\")\n",
    "#make_prediction(model, test_loader, \"submission_.csv\")\n",
    "#import sys\n",
    "#sys.exit()\n",
    "#make_prediction(model, test_loader)\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    train_one_epoch(train_loader, model, optimizer, loss_fn, scaler, config.DEVICE)\n",
    "\n",
    "    # get on validation\n",
    "    preds, labels = check_accuracy(val_loader, model, config.DEVICE)\n",
    "    print(f\"QuadraticWeightedKappa (Validation): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n",
    "\n",
    "    # get on train\n",
    "    preds, labels = check_accuracy(train_loader, model, config.DEVICE)\n",
    "    print(f\"QuadraticWeightedKappa (Training): {cohen_kappa_score(labels, preds, weights='quadratic')}\")\n",
    "\n",
    "    if config.SAVE_MODEL:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint, filename=f\"checkpoints/test 1/b3_{epoch}.pth.tar\")\n",
    "\n",
    "make_prediction(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec21aa71",
   "metadata": {},
   "source": [
    "# Loading pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd4500ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "=> Loading checkpoint\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_FILE = \"checkpoints/test 512/b3_18.pth.tar\"\n",
    "LOAD_MODEL = True\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b3\")\n",
    "model._fc = nn.Linear(1536, 1)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f555f",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a7df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, loader, output_csv=\"submission.csv\"):\n",
    "    preds = []\n",
    "    filenames = []\n",
    "    model.eval()\n",
    "\n",
    "    for x, y, files in tqdm(loader):\n",
    "        x = x.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(x)\n",
    "            # Convert MSE floats to integer predictions\n",
    "            predictions[predictions < 0.5] = 0\n",
    "            predictions[(predictions >= 0.5) & (predictions < 1.5)] = 1\n",
    "            predictions[(predictions >= 1.5) & (predictions < 2.5)] = 2\n",
    "            predictions[(predictions >= 2.5) & (predictions < 3.5)] = 3\n",
    "            predictions[(predictions >= 3.5) & (predictions < 10000000)] = 4\n",
    "            predictions = predictions.long().squeeze(1)\n",
    "            preds.append(predictions.cpu().numpy())\n",
    "            filenames += files\n",
    "\n",
    "    #df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n",
    "    df = pd.DataFrame({\"image\": filenames, \"level\": np.concatenate(preds, axis=0)})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    #model.train()\n",
    "    print(\"Done with predictions\")\n",
    "    \n",
    "    return filenames, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2b045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████▉                                                      | 114/352 [00:22<00:42,  5.65it/s]"
     ]
    }
   ],
   "source": [
    "test_ds = DRDataset(\n",
    "    images_folder=\"data/resized_train/resized_train_512/\",\n",
    "    path_to_csv=\"test_cropped.csv\",\n",
    "    transform=val_transforms,\n",
    "    train=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, num_workers=0, shuffle=False\n",
    ")\n",
    "\n",
    "filesnames, preds = make_prediction(model, test_loader,output_csv=\"output/f_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ee00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filesnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ea6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_y = pd.read_csv('output/f_submission.csv')\n",
    "true_y = pd.read_csv('test_cropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ba396",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38dd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from prettytable import PrettyTable\n",
    "# Test model using test dataset\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "def test(true_y, output_y):\n",
    "    \n",
    "    \n",
    "    test = true_y[\"level\"].values\n",
    "    pred = output_y[\"level\"].values\n",
    "    #Confusion Matrix\n",
    "    print(\" \")\n",
    "    matrix = metrics.confusion_matrix(test, pred)\n",
    "    print(\" \")\n",
    "    print('vgg_Confusion_Matrix:')\n",
    "    print(\" \")\n",
    "    print(matrix)\n",
    "    print(\" \")\n",
    "    \n",
    "    print(\"classification_report: \")\n",
    "    print('-'*40)\n",
    "    print(metrics.classification_report(test, pred))\n",
    "    \n",
    "    print(f\"QuadraticWeightedKappa (test): {cohen_kappa_score(test, pred, weights='quadratic')}\")\n",
    "   \n",
    "    \n",
    "    # Plotting ROC curve\n",
    "    # Binarize the output\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y_test = label_binarize(true_y[\"level\"].values, classes=[0, 1, 2, 3, 4])\n",
    "    y_pred = label_binarize(output_y[\"level\"].values, classes=[0, 1, 2, 3, 4])\n",
    "    n_classes = y_pred.shape[1]\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot ROC for specific class\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Receiver operating characteristic to specific class: class = 0')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(' ')\n",
    "    \n",
    "    # Plot ROC curve for multi class\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Receiver operating characteristic to multi-class')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "print(\"Model is ready to Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2587701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y[\"level\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(true_y, output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fdf40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
